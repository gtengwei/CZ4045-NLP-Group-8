{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fionchai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4952, 3) (500, 3) (500, 3)\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error # comment this if you dont have teh dev_set\n",
    "\n",
    "# import dataset\n",
    "train_set = pd.read_csv('train.csv')\n",
    "\n",
    "test_set = pd.read_csv('test.csv')\n",
    "\n",
    "# from train_set sample development set\n",
    "dev_set = train_set.sample(n=500, replace=False)\n",
    "\n",
    "# remove dev set from train set\n",
    "train_set = train_set.drop(dev_set.index)\n",
    "\n",
    "# check\n",
    "print(train_set.shape, dev_set.shape, test_set.shape)\n",
    "\n",
    "# save to dataframe\n",
    "dev_set.to_csv(\"dev_set.csv\", index=False)\n",
    "train_set.to_csv(\"train_set_modified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train_set_modified.csv')\n",
    "dev_set = pd.read_csv('dev_set.csv')\n",
    "test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data (averaging over word representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec\n",
    "\n",
    "# download the word2vec-google-news-300\n",
    "w2v = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select four classes: 0, 1, 2, 3\n",
    "# 4 and 5 will be OTHERS (4)\n",
    "\n",
    "# for train_set\n",
    "train_set.loc[train_set['label-coarse'] > 4, 'label-coarse'] = 4\n",
    "\n",
    "# for dev_set\n",
    "dev_set.loc[dev_set['label-coarse'] > 4, 'label-coarse'] = 4\n",
    "\n",
    "# for test_set\n",
    "test_set.loc[test_set['label-coarse'] > 4, 'label-coarse'] = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network transforming the input for each word to its final vector representation\n",
    "def token(sentence):  \n",
    "      \n",
    "    # keep only english words\n",
    "    sentence = re.sub(\"[^a-zA-Z]\",\" \",sentence)\n",
    "    \n",
    "    # converting to lower case and splitting\n",
    "\n",
    "    # NEED TO REMOVE STOP WORD?\n",
    "\n",
    "    token = word_tokenize(sentence.lower())\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label-coarse</th>\n",
       "      <th>label-fine</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>[how, did, serfdom, develop, in, and, then, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "      <td>[what, films, featured, the, character, popeye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>[how, can, i, find, a, list, of, celebrities, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>[what, fowl, grabs, the, spotlight, after, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the full form of .com ?</td>\n",
       "      <td>[what, is, the, full, form, of, com]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label-coarse  label-fine  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             0           0   \n",
       "3             1           2   \n",
       "4             2           3   \n",
       "\n",
       "                                                text  \\\n",
       "0  How did serfdom develop in and then leave Russ...   \n",
       "1   What films featured the character Popeye Doyle ?   \n",
       "2  How can I find a list of celebrities ' real na...   \n",
       "3  What fowl grabs the spotlight after the Chines...   \n",
       "4                    What is the full form of .com ?   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  [how, did, serfdom, develop, in, and, then, le...  \n",
       "1  [what, films, featured, the, character, popeye...  \n",
       "2  [how, can, i, find, a, list, of, celebrities, ...  \n",
       "3  [what, fowl, grabs, the, spotlight, after, the...  \n",
       "4               [what, is, the, full, form, of, com]  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['cleaned_text'] = train_set['text'].apply(token)\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label-coarse</th>\n",
       "      <th>label-fine</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>[how, did, serfdom, develop, in, and, then, le...</td>\n",
       "      <td>[0.058892144097222224, 0.010908338758680556, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What films featured the character Popeye Doyle ?</td>\n",
       "      <td>[what, films, featured, the, character, popeye...</td>\n",
       "      <td>[0.024762834821428572, 0.06901332310267858, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>[how, can, i, find, a, list, of, celebrities, ...</td>\n",
       "      <td>[0.02879638671875, 0.0680908203125, 0.01679687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>[what, fowl, grabs, the, spotlight, after, the...</td>\n",
       "      <td>[0.0709991455078125, 0.04058837890625, 0.00234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the full form of .com ?</td>\n",
       "      <td>[what, is, the, full, form, of, com]</td>\n",
       "      <td>[0.016701834542410716, 0.00023978097098214285,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label-coarse  label-fine  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             0           0   \n",
       "3             1           2   \n",
       "4             2           3   \n",
       "\n",
       "                                                text  \\\n",
       "0  How did serfdom develop in and then leave Russ...   \n",
       "1   What films featured the character Popeye Doyle ?   \n",
       "2  How can I find a list of celebrities ' real na...   \n",
       "3  What fowl grabs the spotlight after the Chines...   \n",
       "4                    What is the full form of .com ?   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  [how, did, serfdom, develop, in, and, then, le...   \n",
       "1  [what, films, featured, the, character, popeye...   \n",
       "2  [how, can, i, find, a, list, of, celebrities, ...   \n",
       "3  [what, fowl, grabs, the, spotlight, after, the...   \n",
       "4               [what, is, the, full, form, of, com]   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.058892144097222224, 0.010908338758680556, 0...  \n",
       "1  [0.024762834821428572, 0.06901332310267858, -0...  \n",
       "2  [0.02879638671875, 0.0680908203125, 0.01679687...  \n",
       "3  [0.0709991455078125, 0.04058837890625, 0.00234...  \n",
       "4  [0.016701834542410716, 0.00023978097098214285,...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = train_set['cleaned_text'].str.len().max()\n",
    "\n",
    "# get the embedding shape of the model\n",
    "embed_shape = len(w2v['test'])\n",
    "average_word_embeddings = []\n",
    "\n",
    "for index, row in train_set.iterrows():\n",
    "\n",
    "    sentence = row['cleaned_text']\n",
    "\n",
    "    # get word embedding of each word\n",
    "    word_embeddings = []\n",
    "\n",
    "    for word in sentence:\n",
    "        # check if the word is present in the model\n",
    "        if word in w2v.key_to_index:\n",
    "            word_embeddings.append(w2v[word])\n",
    "        else:\n",
    "             word_embeddings.append(np.zeros(shape=(embed_shape)))\n",
    "    \n",
    "    # perform averaging of word embeddings\n",
    "    awe = np.mean(word_embeddings, axis = 0)\n",
    "    average_word_embeddings.append(awe)\n",
    "\n",
    "train_set['vector'] = average_word_embeddings\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "X_train = train_set['vector']\n",
    "y_train = train_set['label-coarse']\n",
    "\n",
    "X_dev = train_set['vector']\n",
    "y_dev = train_set['label-coarse']\n",
    "\n",
    "# SCALING?\n",
    "\n",
    "# MINI-BATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fed into the softmax classifier to predict the final label\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_d, hidden_d, layer_d, output_d):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_d\n",
    "        self.layer_dim = layer_d\n",
    "\n",
    "        # LSTM model \n",
    "        self.lstm = nn.LSTM(input_d, hidden_d, layer_d, batch_first=True) \n",
    "\n",
    "        self.fc = nn.Softmax(dim = 1) # NOT VERY SURE ABOUT THIS\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    \n",
    "input_dim = embed_shape\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "layer_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCE\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  outputs = model.forward(X_train_tensors_final) #forward pass\n",
    "  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    " \n",
    "  # obtain the loss function\n",
    "  loss = criterion(outputs, y_train_tensors)\n",
    " \n",
    "  loss.backward() #calculates the loss of the loss function\n",
    " \n",
    "  optimizer.step() #improve from loss, i.e backprop\n",
    "  if epoch % 100 == 0:\n",
    "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
