HOW TO RUN THE NOTEBOOKS
These notebooks contains the code for the assignment.
To run these notebook, make sure you have Jupyter installed and open the file in a Jupyter notebook environment.
Then, run each cell in sequential order from the first cell to see the results of the analysis.

HOW TO RUN PYTHON FILE 
train.py contains the code for training of the LSTM model for Task 1.3.
To run the file, make sure you have Python installed and type in python train.py in your command prompt at the file directory.
Please take note this will take around an hour to finish running.

EXPLANATION FOR OUTPUT
The jupyter notebooks contain the sample outputs required for the assignment.
The code has been sectioned nicely into individual cells, with comments to document the respective code and sample outputs.

We have a total of 6 Jupyter notebooks to submit, 1 for Task 1 and 5 for Task 2.
We also have a Python file,train.py, which is used to train the model for Task 1.3, but the explanation and content of the code can be found in the notebook for Task 1.

The notebook for Task 1 is: 
- part1.ipynb
The notebooks for Task 2 with their respective objective are:  
- Aggregation
    - Part_2_max_pooling.ipynb
    - Part_2_average.ipynb
    - Part_2_lastword.ipynb
- Hyperparameter tuning
    - Part_2_LSTM_model.ipynb
    - BiGRU_model_optimization.ipynb

They contain the analysis of the network model architecture, hyperparameter tuning and aggregation methods.

For Task 1.1 and Task 1.2, the detailed explanations for sample outputs can be found in the notebook part1.ipynb.
For Task 1.3 and Task 2, both of these uses a softmax activation function and outputs the probability distribution of their respective classes.
The argmax of the probability distribution will be the predicted label.